{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3312,
     "status": "ok",
     "timestamp": 1646031306314,
     "user": {
      "displayName": "Phuong Dam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01072403895711103873"
     },
     "user_tz": -420
    },
    "id": "umIRFcF5yj0t",
    "outputId": "35a6ce56-7271-4916-f6f4-bb407c634cfa"
   },
   "outputs": [],
   "source": [
    "# !pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1646031306315,
     "user": {
      "displayName": "Phuong Dam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01072403895711103873"
     },
     "user_tz": -420
    },
    "id": "O7kbCSTIyZqX"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import squarify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from underthesea import word_tokenize\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_RMF_preprocessing(df):\n",
    "    # drop rows where Quantity < 0\n",
    "    df = df[df.Quantity >= 0]\n",
    "    # drop rows where CustomerID == null\n",
    "    df = df[df.CustomerID.notnull()]\n",
    "    # drop rows where UnitPrice < 0\n",
    "    df = df[df.UnitPrice >= 0]\n",
    "    # drop duplicated rows\n",
    "    df = df.drop_duplicates()\n",
    "    # Convert column 'InvoiceDate' to datetime datatype\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    # convert InvoiceNo data type to integer\n",
    "    df.InvoiceNo = df.InvoiceNo.astype(int)\n",
    "    # Create new column 'Amount'\n",
    "    df['Amount'] = df['Quantity'] * df['UnitPrice']\n",
    "    # Get max date of dataframe\n",
    "    max_date = df['InvoiceDate'].max().date()\n",
    "    # Calculate R, F, M\n",
    "    Recency = lambda x: (max_date - x.max().date()).days\n",
    "    Frequency = lambda x: x.nunique()\n",
    "    Monetary = lambda x: round(sum(x),2)\n",
    "\n",
    "    df_RFM = df.groupby('CustomerID').agg({'InvoiceDate' : Recency,\n",
    "                                        'InvoiceNo' : Frequency,\n",
    "                                        'Amount' : Monetary,\n",
    "                                        })\n",
    "    # Rename column names\n",
    "    df_RFM.columns = ['Recency', 'Frequency', 'Monetary']\n",
    "    df_RFM = df_RFM.sort_values('Monetary', ascending=False)\n",
    "    return df_RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average values for each GMM_segment, and return a size of each segment \n",
    "def create_df_agg(df, groupby_col):\n",
    "    df.R = df.R.astype(int)\n",
    "    df.F = df.F.astype(int)\n",
    "    df.M = df.M.astype(int)\n",
    "    \n",
    "    df_agg = df.groupby(groupby_col).agg({\n",
    "      'Recency': 'mean',\n",
    "      'Frequency': 'mean',\n",
    "      'Monetary': 'mean',\n",
    "      'R': 'mean',\n",
    "      'F': 'mean',\n",
    "      'M': ['mean', 'count']}).round(0)\n",
    "\n",
    "    df_agg.columns = df_agg.columns.droplevel()\n",
    "    df_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean', 'RMean','FMean','MMean','Count']\n",
    "    df_agg['Percent'] = round((df_agg['Count']/df_agg.Count.sum())*100, 2)\n",
    "\n",
    "    # Reset the index\n",
    "    df_agg = df_agg.reset_index()\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1646031306316,
     "user": {
      "displayName": "Phuong Dam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01072403895711103873"
     },
     "user_tz": -420
    },
    "id": "XXQOe4YYyWQQ"
   },
   "outputs": [],
   "source": [
    "# Visualization - Treemap\n",
    "def treemap_customer_segmentation(df_agg,font_size):\n",
    "    #Create our plot and resize it.\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.add_subplot()\n",
    "    fig.set_size_inches(22, 9)\n",
    "\n",
    "    # create a color palette, mapped to these values\n",
    "    cmap = matplotlib.cm.plasma\n",
    "    norm = matplotlib.colors.Normalize(vmin=min(df_agg['Count']), vmax=max(df_agg['Count']))\n",
    "    colors = [cmap(norm(value)) for value in df_agg['Count']]\n",
    "\n",
    "    squarify.plot(sizes=df_agg['Count'],\n",
    "                text_kwargs={'fontsize':font_size,'weight':'bold', 'fontname':\"sans serif\"},\n",
    "                color=colors,\n",
    "                label=['{} \\n{:.0f} days \\n{:.0f} orders \\n{:.0f} $ \\n{:.0f} customers ({}%)'.format(*df_agg.iloc[i])\n",
    "                        for i in range(0, len(df_agg))], alpha=0.5 )\n",
    "\n",
    "\n",
    "    plt.title(\"Customers Segments\",fontsize=26,fontweight=\"bold\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plt.savefig('RFM Segments.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_cont_analysis(vars,df):\n",
    "    results = []\n",
    "    for var in vars:\n",
    "        mean = df[var].mean()\n",
    "        median = df[var].median() \n",
    "        mode = df[var].mode()\n",
    "        max_val = df[var].max()\n",
    "        min_val = df[var].min()\n",
    "        range_val = np.ptp(df[var])\n",
    "        variance = df[var].var()\n",
    "        skewness = df[var].skew()\n",
    "        kurtosis = df[var].kurtosis()\n",
    "        result = [var, mean,median,mode,max_val,min_val,range_val,variance,skewness,kurtosis]\n",
    "        results.append(result)\n",
    "        df_result = pd.DataFrame(results, columns=['var_name','mean','median','mode','max_val','min_val',\n",
    "                                                  'range_val','variance','skewness','kurtosis'],\n",
    "                                ).set_index('var_name')\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization - distplot\n",
    "def visualization_distplot(vars,df):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    for i in range(1,len(vars)+1):\n",
    "        plt.subplot(1,3,i)\n",
    "        sns.distplot(df[vars[i-1]].dropna())\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization - boxplot\n",
    "def visualization_boxplot(vars,df):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    for i in range(1,len(vars)+1):\n",
    "        plt.subplot(1,3,i)\n",
    "        plt.boxplot(df[vars[i-1]].dropna())\n",
    "        plt.xlabel(str(vars[i-1]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(text, list_to_remove):\n",
    "    #xoá bỏ ký tự đặc biệt\n",
    "    text = re.sub('[\\-\\–\\,\\+\\?\\%\\/\\•\\*\\&\\[\\]\\(\\)\\:\\;]', ' ', text).replace('v.',' ').replace('...',' ').replace('.',' ').replace('…',' ')\n",
    "    #lowercase và tách riêng các câu phân cách bởi '\\n'\n",
    "    text = text.lower().split('\\n')\n",
    "    #loại bỏ khoảng trắng ở đầu và cuối mỗi câu\n",
    "    text = [e.strip() for e in text]\n",
    "    #loại bỏ các câu trùng nhau\n",
    "    text = list(set(text) - set(list_to_remove))\n",
    "    #loại bỏ các câu chứa 'sku'\n",
    "    text = [e for e in text if 'sku' not in e]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_preparation(clean_df,stop_words):\n",
    "    # Tokenize(split) sentence into words\n",
    "    products_gen = [[text for text in x.split()] for x in clean_df['content_wt']]\n",
    "    \n",
    "    # remove some more special elements & stopwords \n",
    "    products_gen_re = [[t.lower() for t in text if not t in ['', ' ','thương hiệu','xuất xứ']] for text in  products_gen] # ký tự đặc biệt\n",
    "    products_gen_re = [[t for t in text if not t in stop_words] for text in products_gen_re] # stopword\n",
    "    \n",
    "    # Obtain the number of features based on dicjtionary: use corpora.Dictionary\n",
    "    dictionary = corpora.Dictionary(products_gen_re)\n",
    "    \n",
    "    # Numbers of features (word) in dictionary\n",
    "    feature_cnt = len(dictionary.token2id)\n",
    "    \n",
    "    # Obtain corpus based on dictionary (dense matrix)\n",
    "    corpus = [dictionary.doc2bow(text) for text in products_gen_re]\n",
    "    \n",
    "    # Use TF-IDF to process corpus, obtaining index\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "    # Tính toán sự tương tự trong ma trận thưa thớt\n",
    "    index_sparse_matrix = similarities.SparseMatrixSimilarity(tfidf[corpus],\n",
    "                                               num_features=feature_cnt)\n",
    "    return tfidf, dictionary, index_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When user choose one product\n",
    "def get_recommendation(clean_df, original_df, tfidf, dictionary, index_sparse_matrix, i):\n",
    "    \"\"\"\n",
    "    Gợi ý 5 sản phẩm có độ tương đồng cao nhất \n",
    "    \"\"\"\n",
    "    # sản phẩm đang xem\n",
    "    name_description_pre = clean_df.iloc[[i]]['content_wt'][i]\n",
    "    view_product = name_description_pre.lower().split()\n",
    "\n",
    "    # convert search words into Sparse Vectors\n",
    "    kw_vector = dictionary.doc2bow(view_product)\n",
    "\n",
    "    # similarity calculation\n",
    "    sim = index_sparse_matrix[tfidf[kw_vector]]\n",
    "    \n",
    "    # 5 sản phẩm có sim cao nhất (không tính sản phẩm chọn có index -1)\n",
    "    indexes = sim.argsort()[-6:-1]\n",
    "    result = original_df[['item_id', 'name', 'description', 'rating', 'price', 'list_price', 'brand', 'group','url']].iloc[sim.argsort()[-6:-1]]\n",
    "    print('*** SELECTED PRODUCT ***')\n",
    "    display(original_df[['item_id', 'name', 'description', 'rating', 'price', 'list_price', 'brand', 'group','url']].iloc[[i]])\n",
    "    print('*** 5 RECOMMENDED PRODUCTS ***')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_function(original_df, stop_words):\n",
    "    \"\"\"\n",
    "    Dùng hàm \"TfidfVectorizer\" để chuẩn hóa \"content_wt\" với:\n",
    "    + analyzer='word': chọn đơn vị trích xuất là word\n",
    "    + ngram_range=(1, 1): mỗi lần trích xuất 1 word\n",
    "    + min_df=0: tỉ lệ word không đọc được là 0\n",
    "    Lúc này ma trận trả về với số dòng tương ứng với số sp và số cột tương ứng với số từ được tách ra từ \"content_wt\"\n",
    "    \"\"\"\n",
    "    tf = TfidfVectorizer(analyzer='word', stop_words=stop_words, min_df=0)\n",
    "    tfidf_matrix = tf.fit_transform(original_df['content_wt'])\n",
    "\n",
    "    \"\"\"\n",
    "    Dùng hàm \"linear_kernel\" để tạo thành ma trận hình vuông với số hàng và số cột là số lượng sp\n",
    "    để tính toán điểm tương đồng giữa từng sp với nhau\n",
    "    \"\"\"\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# với mỗi sản phẩm, lấy 5 sản phẩm tương quan nhất\n",
    "def cosine_recommendation(original_df,cosine_similarities,i):\n",
    "    results = {}\n",
    "    for idx, row in original_df.iterrows():    \n",
    "        similar_indices = cosine_similarities[idx].argsort()[-6:-1]\n",
    "        similar_items = [(cosine_similarities[idx][e]) for e in similar_indices]\n",
    "        similar_items = [(cosine_similarities[idx][e], original_df.index[e]) for e in similar_indices]\n",
    "#         print(similar_items[0:])\n",
    "        results[idx] = similar_items[0:]\n",
    "    print('*** SELECTED PRODUCT ***')\n",
    "    display(original_df[['item_id', 'name', 'description', 'rating', 'price', 'list_price', 'brand', 'group','url']].iloc[[i]])\n",
    "    print('*** 5 RECOMMENDED PRODUCTS ***')\n",
    "    return original_df[['item_id', 'name', 'description', 'rating', 'price', 'list_price', 'brand', 'group','url']].iloc[[e[1] for e in results[i]]]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOtAbdxSgHLjyvW0keswJ7g",
   "collapsed_sections": [],
   "name": "Lib.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
